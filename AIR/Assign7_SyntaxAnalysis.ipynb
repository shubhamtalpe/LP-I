{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz (12.0 MB)\n",
      "Requirement already satisfied (use --upgrade to upgrade): en-core-web-sm==2.2.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz in c:\\programdata\\anaconda3\\lib\\site-packages\n",
      "Requirement already satisfied: spacy>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from en-core-web-sm==2.2.0) (2.3.4)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (1.0.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (2.24.0)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (7.4.3)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (1.1.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (1.18.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (2.0.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (4.47.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (3.0.4)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (49.2.0.post20200714)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (0.8.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (1.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0; python_version >= \"3.6\" in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (0.7.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en-core-web-sm==2.2.0) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en-core-web-sm==2.2.0) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en-core-web-sm==2.2.0) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en-core-web-sm==2.2.0) (3.0.4)\n",
      "Building wheels for collected packages: en-core-web-sm\n",
      "  Building wheel for en-core-web-sm (setup.py): started\n",
      "  Building wheel for en-core-web-sm (setup.py): finished with status 'done'\n",
      "  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.2.0-py3-none-any.whl size=12019125 sha256=0b5c995994683d0d47d5d2f1fed5067f5e9864a468797159e7c2b850471d2dbc\n",
      "  Stored in directory: c:\\users\\stalp\\appdata\\local\\pip\\cache\\wheels\\fc\\31\\e9\\092e6f05b2817c9cb45804a3d1bf2b9bf6575742c01819337c\n",
      "Successfully built en-core-web-sm\n"
     ]
    }
   ],
   "source": [
    "!pip3 install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\spacy\\util.py:275: UserWarning: [W031] Model 'en_core_web_sm' (2.2.0) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.4). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Core English Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I Love Coding.\n",
      "Geeks for Geeks helped me in this regard very much.\n",
      "I Love Geeks for Geeks.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"I Love Coding. Geeks for Geeks helped me in this regard very much. I Love Geeks for Geeks.\") \n",
    "\n",
    "for sent in doc.sents: \n",
    "  print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\stalp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'Love', 'Coding', '.', 'Geeks', 'for', 'Geeks', 'helped', 'me', 'in', 'this', 'regard', 'very', 'much', '.', 'I', 'Love', 'Geeks', 'for', 'Geeks', '.']\n"
     ]
    }
   ],
   "source": [
    "text = \"I Love Coding. Geeks for Geeks helped me in this regard very much. I Love Geeks for Geeks.\"\n",
    "tokenized_text = word_tokenize(text)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Syntactic Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('Love', 'VBP'),\n",
       " ('Coding', 'VBG'),\n",
       " ('.', '.'),\n",
       " ('Geeks', 'NNP'),\n",
       " ('for', 'IN'),\n",
       " ('Geeks', 'NNP'),\n",
       " ('helped', 'VBD'),\n",
       " ('me', 'PRP'),\n",
       " ('in', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('regard', 'NN'),\n",
       " ('very', 'RB'),\n",
       " ('much', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('Love', 'VBP'),\n",
       " ('Geeks', 'NNP'),\n",
       " ('for', 'IN'),\n",
       " ('Geeks', 'NNP'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Syntactic parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\stalp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag, word_tokenize, RegexpParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sample = \"The quick brown fox jumps over the lazy dog\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_text = pos_tag(word_tokenize(text_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "print(tagged_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract parts of speect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = RegexpParser(\"\"\"\n",
    "                        NP: {<DT>?<JJ>*<NN>}    #To extract Noun Phrases \n",
    "                        P: {<IN>}               #To extract Prepositions\n",
    "                        V: {<V.*>}              #To extract Verbs\n",
    "                        PP: {<P> <NP>}          #To extract Prepostional Phrases\n",
    "                        VP: {<V> <NP|PP>*}      #To extarct Verb Phrases\n",
    "                        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Extracting\n",
      " (S\n",
      "  (NP The/DT quick/JJ brown/NN)\n",
      "  (NP fox/NN)\n",
      "  (VP (V jumps/VBZ) (PP (P over/IN) (NP the/DT lazy/JJ dog/NN))))\n"
     ]
    }
   ],
   "source": [
    "output = chunker.parse(tagged_text)\n",
    "print(\"After Extracting\\n\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
